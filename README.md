# MajorSignL - Real-Time Sign Language Recognition with Face Recognition

A real-time AI system that combines **Sign Language Recognition** using MediaPipe and Transformer models with **Face Recognition** for person identification.

## ğŸš€ Features

- **Real-Time Sign Language Recognition**: Transformer-based model for recognizing sign language gestures
- **Face Recognition**: Identify people from pre-loaded face datasets organized by person folders
- **MediaPipe Integration**: Real-time pose, hand, and face landmark detection with smoothing filters
- **GPU Acceleration**: CUDA support for RTX 4060 and other NVIDIA GPUs
- **WebSocket Streaming**: Real-time video processing with web interface
- **REST API**: Complete API for managing faces and signs
- **Performance Monitoring**: FPS tracking and processing time metrics

## ğŸ“ Project Structure

```
majorSignL/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ fase_data/           # Person folders with face images
â”‚   â”‚   â”‚   â”œâ”€â”€ Person Name 1/   # Folder named after person
â”‚   â”‚   â”‚   â”œâ”€â”€ Person Name 2/   # Contains 10+ images per person
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ models/              # Pre-trained models
â”‚   â”‚   â””â”€â”€ training/            # Sign language training data
â”‚   â””â”€â”€ majorSignL/
â”‚       â”œâ”€â”€ api/                 # FastAPI server
â”‚       â”œâ”€â”€ models/              # Face & sign processors
â”‚       â”œâ”€â”€ utils/               # MediaPipe & filters
â”‚       â””â”€â”€ frontend/            # Web interface
â”œâ”€â”€ env.yml                      # Conda environment (SignL)
â”œâ”€â”€ start_server.sh             # Linux startup script
â””â”€â”€ start_server.ps1            # Windows startup script
```

## ğŸ› ï¸ Setup & Installation

### 1. Environment Setup (WSL2 + CUDA)

```bash
# Create conda environment
mamba env create -f env.yml

# Activate environment
mamba activate SignL

# Verify CUDA setup
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'Device: {torch.cuda.get_device_name(0)}')"
```

### 2. Face Recognition Setup

Your face data should be organized like this:
```
src/data/fase_data/
â”œâ”€â”€ Aishwarya A/
â”‚   â”œâ”€â”€ aish (1).jpg
â”‚   â”œâ”€â”€ aish (2).jpg
â”‚   â””â”€â”€ ... (10+ images)
â”œâ”€â”€ Chandra Shekara/
â”‚   â”œâ”€â”€ chandra (1).jpg
â”‚   â””â”€â”€ ... (10+ images)
â””â”€â”€ Nraju/
    â”œâ”€â”€ nagabhushana (1).jpg
    â””â”€â”€ ... (10+ images)
```

The system will:
- Automatically load faces from person-named folders
- Create face encodings for each person using multiple images
- Cache encodings for faster startup
- Use face_recognition library with dlib

### 3. Sign Language Model Training

```bash
# Train the transformer model (if you have training data)
python src/majorSignL/train_model.py

# The model will be saved as:
# src/data/models/sign_language_transformer.pt
```

## ğŸ”§ Advanced Features

### Face Recognition Models Integration
The system supports additional pre-trained face models:
- **FaceNet**: 177 embeddings loaded from `ds_model_facenet_detector_opencv_aligned_normalization_base_expand_0.pkl`
- **VGGFace**: 51 embeddings loaded from `ds_model_vggface_detector_opencv_aligned_normalization_base_expand_0.pkl`
- **VGG16**: Available but currently empty

These models provide additional verification for face recognition accuracy.

## ğŸš€ Running the Server

### Linux/WSL2:
```bash
chmod +x start_server.sh
./start_server.sh
```

### Windows:
```powershell
.\start_server.ps1
```

### Manual Start:
```bash
mamba activate SignL
cd src
python -m uvicorn majorSignL.api.main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸŒ API Endpoints

### Core Endpoints
- `GET /` - System status and capabilities
- `WebSocket /ws` - Real-time video processing
- `GET /static/index.html` - Web interface

### Face Recognition
- `GET /faces` - List known faces and info
- `POST /faces/refresh` - Refresh face cache
- `GET /debug/face-paths` - Debug face data paths

### Sign Language
- `GET /signs` - Sign classifier information  
- `POST /signs/reset` - Reset current sign sequence
- `POST /signs/confidence/{threshold}` - Set confidence threshold

## ğŸ¯ Usage

1. **Start Server**: Run startup script
2. **Open Browser**: Go to `http://localhost:8000/static/index.html`
3. **Enable Camera**: Allow browser camera access
4. **Real-Time Processing**: 
   - Face recognition runs every 5th frame for performance
   - Sign recognition runs every 2nd frame
   - MediaPipe runs on every frame with filtering

## ğŸ”§ Configuration

### Face Recognition Tuning
- **Threshold**: Adjust face matching threshold (default: 0.5)
- **Cache**: Face encodings are cached for faster startup
- **Performance**: Uses HOG model for speed, CNN for accuracy

### Sign Language Tuning  
- **Confidence**: Set prediction confidence threshold
- **Sequence Length**: 30 frames per sign (configurable)
- **Model**: Transformer architecture with attention

### Performance Optimization
- **GPU**: CUDA acceleration for PyTorch operations
- **Filtering**: One Euro Filter for landmark smoothing
- **Frame Skipping**: Different processing rates per component

## ğŸ› Troubleshooting

### Face Recognition Issues
```bash
# Check if faces are loading
curl http://localhost:8000/debug/face-paths

# Refresh face cache
curl -X POST http://localhost:8000/faces/refresh

# Verify face_recognition installation
python -c "import face_recognition; print('OK')"
```

### CUDA Issues
```bash
# Check CUDA availability
python -c "import torch; print(torch.cuda.is_available())"

# Check CUDA version compatibility
nvidia-smi
python -c "import torch; print(torch.version.cuda)"
```

### Performance Issues
- **Reduce frame rates**: Modify frame skipping intervals in main.py
- **Lower resolution**: Adjust frame resize in face_processor.py  
- **Disable features**: Comment out face/sign processing temporarily

## ğŸ“Š Performance Metrics

Expected performance on RTX 4060:
- **Overall FPS**: ~7-8 FPS
- **MediaPipe**: ~10-15ms per frame
- **Face Recognition**: ~50-100ms (every 5th frame)
- **Sign Classification**: ~20-40ms (every 2nd frame)

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Test with your GPU/environment
4. Submit pull request

## ğŸ“ License

- Proprarity Lisence 

---

**System Requirements:**
- Python 3.11
- NVIDIA GPU with CUDA support
- 8GB+ RAM
- Webcam for real-time processing

## Owner & Auther 
- Shri: Nagabhushana Raju S 

![alt text](image.png)